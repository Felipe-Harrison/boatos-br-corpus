{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerais\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time as now\n",
    "from colorama import Fore, Style\n",
    "start_time = now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Imports: Buscar novos boatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawlers\n",
    "from Modulos.Crawlers.BoatosCrawler import BoatosCrawler\n",
    "# Rotular os boatos\n",
    "from Modulos.RotularBoatos import Rotulador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler Base de dados\n",
    "BASE_DE_DADOS_ATUAL = \"../base_simples/boatos_br_corpus_simples.json\"\n",
    "base_carregada = pd.read_json(BASE_DE_DADOS_ATUAL)\n",
    "# Urls para procurar\n",
    "URLS_INICIAIS = [\n",
    "    \"https://www.boatos.org/\",\n",
    "]\n",
    "ULTIMA_DATA_ATUAL_BASE = datetime.fromisoformat(base_carregada[\"data-publicacao\"][0])\n",
    "# Path salvar bases\n",
    "BASE_SIMPLES_PATH = \"../base_simples/boatos_br_corpus_simples_att.json\"\n",
    "BASE_COMPLETA_PATH = \"../base_completa/boatos_br_corpus_att.json\"\n",
    "BASE_PROCESSADA_PATH = \"../base_processada/boatos_br_corpus_processada_att.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StopWords\n",
    "nltk.download('stopwords')\n",
    "stopwords_portugues = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Buscar novos boatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Configurando Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawlerBoatos = BoatosCrawler(urlsIniciais=URLS_INICIAIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Buscando novos boatos\n",
    "! Busca apenas boatos que tem data superior a data de publicação do boato mais recente da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novosBoatos = []\n",
    "# Buscar noticias novas -> Que não estão na base\n",
    "novosBoatos = crawlerBoatos.scrape(dateToStop=ULTIMA_DATA_ATUAL_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Normalizando novos textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lógica de limpeza\n",
    "* Selecionar apenas letras (remover pontuação, números e outros caracteres)\n",
    "* Transformar palavras em minusculo\n",
    "* Remover stopwords\n",
    "* Manter emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscaPalavras(texto:str) -> str:\n",
    "    palavrasMinusculas = re.findall(r'\\b[A-zÀ-úü]+\\b', texto.lower())\n",
    "    textoLimpo = [w for w in palavrasMinusculas if w not in stopwords_portugues]\n",
    "    return \" \".join(textoLimpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotulação dos boatos encontrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lógica da rotulação\n",
    "* Analisar se no texto possui alguma das frases presentes nos dicionários criados\n",
    "\n",
    "> ./Modulos/RotularBoatos/DicionarioFrasesCategoria.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIASBOATOSFALSO = [\n",
    "    \"Fake news\",\n",
    "    \"fake news\",\n",
    "    \"Boato sem comprovação\",\n",
    "    \"Golpe\", \n",
    "    \"Enganoso\", \n",
    "    \"Exagerado\", \n",
    "    \"é falso\",\n",
    "    \"é falsa\",\n",
    "    \"não é verdade\",\n",
    "    \"não procede\",\n",
    "    \"não há provas\"\n",
    "]\n",
    "CATEGORIASBOATOSVERDADE = [\n",
    "    \"Verdadeiro\", \n",
    "    \"Real com erros\",\n",
    "    \"É fato\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Construindo o objeto dos novos textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos do textos na base BoatosBrData\n",
    "- **url**: URL de onde foi obtido o texto.\n",
    "- **data-publicacao**: Data em que foi publicada a checagem do texto.\n",
    "- **origem**:  De qual site foi retirado\n",
    "- **categorias**: Categorias do boato, por exemplo: Política, Saúde, Mundo, entre outras.\n",
    "- **texto**: Texto original do boato que esta circulando na internet\n",
    "- **texto-normalizado**: Texto normalizado e limpo.\n",
    "- **rotulo**: Atributo alvo da previsão, podendo ser Verdadeiro ou Falso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Class.boatosBrData import BoatosBrData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Transformando novos boatos em BoatosBrData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_normalizados = []\n",
    "# Transformação dos boatos encontrados nas páginas\n",
    "for boato in novosBoatos:\n",
    "    \n",
    "    new_boatosBrData = BoatosBrData(\n",
    "        url= boato['url'],\n",
    "        dataPublicacao= boato['data-publicacao'],\n",
    "        origem='boatosorg',\n",
    "        categorias= boato['categorias'],\n",
    "        texto= boato['referencia'],\n",
    "        textoNormalizado= buscaPalavras(boato['referencia']),\n",
    "        rotulo= Rotulador.AplicarRotulo(boato)\n",
    "    )\n",
    "    boatosBrData_dict = new_boatosBrData.getData()\n",
    "    \n",
    "    # Informar quais noticias devem ser rotuladas manualmente\n",
    "    if(boatosBrData_dict['rotulo'] == \"NDA\"):\n",
    "        print(\"[ROTULAR] Não foi possível rotular: \", boatosBrData_dict['url'])\n",
    "    dados_normalizados.append(boatosBrData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Limpar boatos vazios da nova base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar em DataFrame e remover da base, boatos que estão com dados faltando.\n",
    "novaBaseDF = pd.DataFrame(dados_normalizados)\n",
    "novaBaseDF= novaBaseDF[novaBaseDF['texto'] != '']\n",
    "novaBaseDF.dropna()\n",
    "novaBaseDict = novaBaseDF.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Salvar base com dados simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_SIMPLES_PATH,'w+',encoding=\"utf8\") as f:\n",
    "    json.dump(novaBaseDict,f,indent=3,allow_nan=True,ensure_ascii = False)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Complementando a base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Extrair novas informações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Novas informações extraídas do texto\n",
    "- Quantidade de emojis\n",
    "- Quantidade de palavras\n",
    "- Quantidade de palavras em maiusculo \n",
    "- Quantidade de verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modulos.ComplementarBoatos.Complementador import getNumeroEmojis, getNumeroPalavras, getNumeroPalavrasMaiusculo, getNumeroVerbos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Extraindo novas informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in novaBaseDict:\n",
    "    data['num-emojis'] = getNumeroEmojis(data['texto'])\n",
    "    data['num-verbos'] = getNumeroVerbos(data['texto'])\n",
    "    data['num-palavras'] = getNumeroPalavras(data['texto'])\n",
    "    data['num-palavras-maiusculas'] = getNumeroPalavrasMaiusculo(data['texto'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Salvar base completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_COMPLETA_PATH,'w+',encoding=\"utf8\") as f:\n",
    "    json.dump(novaBaseDict,f,indent=3,allow_nan=True,ensure_ascii = False)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Pre processar a base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Analisar base pelos dicionários de informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(path:str):\n",
    "    aux = []\n",
    "    with open(path,'r') as f:\n",
    "        aux = json.load(f)\n",
    "        f.close()\n",
    "    return aux\n",
    "\n",
    "def normalizarDadoProcessado(dado:str,listaNormalizacao:dict) -> int:\n",
    "    return listaNormalizacao[dado] if listaNormalizacao.get(dado) != None else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Categorias na base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoriasDict = loadJson(\"./Processados/categorias/categorias_processadas.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Origens na base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origensDict = loadJson(\"./Processados/origem/origens_processadas.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Rotulos na base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotulosDict = {\n",
    "    'falso': 0,\n",
    "    'verdade': 1,\n",
    "    'meia-verdade': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Pre processar base completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Lógica de pre processamento\n",
    "- Transformar os seguintes campos da base em valores numéricos:\n",
    "    - rotulo\n",
    "    - data-publicacao\n",
    "    - origem\n",
    "    - categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Pre processando os textos da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in novaBaseDict:\n",
    "    data['categorias'] = [normalizarDadoProcessado(x,categoriasDict) for x in data['categorias']]\n",
    "    data['origem'] = normalizarDadoProcessado(data['origem'],origensDict)\n",
    "    data['data-publicacao'] = pd.to_datetime(data['data-publicacao']).timestamp()\n",
    "    data['rotulo'] = normalizarDadoProcessado(data['rotulo'],rotulosDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Salvar base processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_PROCESSADA_PATH,'w',encoding=\"utf8\") as f:\n",
    "    json.dump(novaBaseDict,f,indent=2,allow_nan=True,ensure_ascii = False,separators=(',', ':'))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Nova Base completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = now()\n",
    "duration = end_time - start_time\n",
    "print(f\"A duração total de execução foi: {duration} segundos\")\n",
    "\n",
    "paths = [BASE_SIMPLES_PATH,BASE_COMPLETA_PATH,BASE_PROCESSADA_PATH]\n",
    "for path in paths:\n",
    "    text = Fore.RED + \"Erro nao foi salvo\"\n",
    "    if(os.path.exists(path)):\n",
    "        text = Fore.GREEN + \"Salvo com sucesso!\"\n",
    "    print(f\"{path} {text}\",Style.RESET_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
